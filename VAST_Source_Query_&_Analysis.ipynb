{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d162fc8-b8a3-4b19-8448-0882ca6aaf57",
   "metadata": {},
   "source": [
    "## VAST Source Query & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38043fb5-2b43-480c-ba73-e143bb2a0081",
   "metadata": {},
   "source": [
    "This Notebook is for testing Radio lightcurve plotting for crossmatched VAST sources, printing png cutouts for said sources, as well as producing an Eta-V scatterplot for a family of sources to see the variability and statistical significance of them.\n",
    "\n",
    "At the moment, with the current imports and code, plotting Radio lightcurves and producing png cutouts for a given source is working ok. Eta-V plots are functional, but take a long time to produce. A current goal is to produce a kernel density distribution in lieu of a scatterplot to save having to replot everything everytime. I want to see how a specific family of transients fares under the statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd21006-3b08-4d4c-af1b-c08a1ceb20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from vasttools.pipeline import Pipeline\n",
    "from vasttools.query import Query\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import show\n",
    "from astropy.coordinates import Angle, SkyCoord\n",
    "from astropy import units as u\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3666fa08-df04-4a49-b575-1d3069f3acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just check and make sure you're in the right directory to load cmf.\n",
    "#use os.chdir(pathname) if you need to change it\n",
    "os.chdir('Project_VAST_FINK')\n",
    "os.getcwd()\n",
    "#alternatively, change the pathfile in the line below to where the .picklefile is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206a0c12-fcf2-49a3-9d0a-4c2d5907393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = pd.read_pickle('Fink_2020_sources_matched_to_VAST_all_sources.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fcba92-3155-4718-8c33-d9cf4a8e6519",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro.family_sort(cms)\n",
    "print(cms.groupby('family').size().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d62b39-fefb-4595-a556-854bbc5dacec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we want analysis for a particular family, use this line\n",
    "family_list=cms.query('family == \"AGN\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc82a67a-001f-4cc5-b4c7-62280b5a0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will automatically find the base directory where all the runs are stored:\n",
    "pipe=Pipeline()\n",
    "#We can also load specific runs from the VAST pipeline:\n",
    "my_run=pipe.load_run('tiles_corrected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8aea0-5406-4c0f-b600-00b1145264c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since matched id list is a list of strings, astype() converts them into intergers first\n",
    "matched_ids=family_list['matched_id'].astype('int64').to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b4f7d-3d7d-4b2b-911d-26311c56c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating sources in the 'tiles_corrected' run that have the same id\n",
    "my_sources=my_run.sources.loc[matched_ids]\n",
    "my_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195da1f2-e31f-4d51-a464-83670fe36f5d",
   "metadata": {},
   "source": [
    "## Eta - V Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4732da-dc35-4c8a-8c3a-3a50839d14c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the query string passed into the below function, which restricts the detected sources considered in the analysis. \n",
    "#Feel free to modify for different science goals.\n",
    "my_query_string = (\n",
    "    \"n_measurements >= 3 \"\n",
    "    \"& n_selavy >= 2 \" # source finder ~ ML\n",
    "    \"& n_neighbour_dist > 1./60.\"\n",
    "    \"& 0.8 < avg_compactness < 1.4 \"\n",
    "    \"& n_relations == 0\"\n",
    "    \"& max_snr >= 5.0\"\n",
    "    \"& v_peak > 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b899633d-204d-46b1-949a-c2e47a5de557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just remember to run output_notebook() from bokeh in order to plot the results using Bokeh \n",
    "eta_thresh, v_thresh, eta_v_candidates, plot = my_run.run_eta_v_analysis(\n",
    "    1.0, \n",
    "    1.0, \n",
    "    query=my_query_string,\n",
    "    plot_type='matplotlib' #comment this out if you want Bokeh\n",
    ")\n",
    "print('eta_thresh =',eta_thresh,', v_thresh = ',v_thresh)\n",
    "print('The number of candidates is', len(eta_v_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09f6a70-156f-423f-afd6-8f3ae6fc55ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3efc3-f4cf-4c3c-b956-51e45ebbb69d",
   "metadata": {},
   "source": [
    "At this point, we've plotted all the radio sources from the run with SNR>0 onto the plot. It takes a very long time for the analysis to finish. Dougal has suggested using a kernel density estimate that, while taking a long time, can be saved and replotted instantaneously. (kind of like saving a png)\n",
    "\n",
    "Now, I want to plot the crossmatched FINK sources on this plot at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f788ea8-e0b1-4990-82ef-a3feba3f288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This makes a list of all the matched_id's as intergers\n",
    "listFinkmatched = cms.matched_id.astype(int).values.tolist()\n",
    "listFinkmatched\n",
    "\n",
    "#should be the same length as the original crossmatched source file\n",
    "len(listFinkmatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73793fbe-d1d5-4800-9771-78d8b10d22e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this creates an arrray of sources from my_run that have the same ids as the catalogue, with the necessary eta and V information\n",
    "#for the plot\n",
    "sel=my_run.sources[my_run.sources.index.isin(listFinkmatched)]\n",
    "print(len(sel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a14056-1a2a-4fc5-a16d-22dc41485663",
   "metadata": {},
   "source": [
    "You may notice by this point that the length of sel and listFinkmatched are not the same. This is because there are duplicate sources: unique FINK IDs assigned to the same VAST IDs. For the catalouge we looked at, there were approx. 60 sources that were duplicates, due to precision errors in identifying sources on FINKs part. This is looked at later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a4485d-1d94-49fe-916b-4e8e80053d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_2.axes[0] gives the axes for the plot, .scatter makes the scatterplot. since the axes are logarithmic (base 10), we\n",
    "#have to take the log10 of each value of \"eta_peak\" and \"v_peak\" from sel.\n",
    "plot.axes[0].scatter(np.log10(sel[\"eta_peak\"]),np.log10(sel[\"v_peak\"]), color='red',zorder=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e01247-c576-45e9-bb4d-b49e6fbed07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d855a9-af2f-48be-b827-9a0673edd690",
   "metadata": {},
   "source": [
    "Next, I want to try and take a subset of the plotted FINK sources under a particular family (like AGN) to see how the distribution looks. Note that you will have to clear all variables (which effectively means restarting the Kernel) to prevent multiple scatterplots being stacked on the same axis. Its recommended you save a given scatterplot to view later without having to rerun the whole notebook.\n",
    "\n",
    "The below section can be run independantly of the above plotting if you just want a scatterplot of the given family sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a740afc2-f429-4196-aead-8f37b04b5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simillar method as before, Im going to define the set of matched ids from the catalogue that belong to a given family\n",
    "listFinkmatched_family=cms.query('family == \"AGN\"').matched_id.astype(int).values.tolist()\n",
    "\n",
    "#again, the length of this should be equal to the number of family sources in the original catalogue\n",
    "len(listFinkmatched_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd7b20-8466-46d4-ad53-df1343185273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as before, define a new array of selected sources, this time for a specific family:\n",
    "sel_family=my_run.sources[my_run.sources.index.isin(listFinkmatched_family)]\n",
    "\n",
    "len(sel_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2294e31e-ac73-4c19-b77e-701950c83754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally, plot them as before. This time the dots are green to differentiate them from the other plot:\n",
    "plot.axes[0].scatter(np.log10(sel_family[\"eta_peak\"]),np.log10(sel_family[\"v_peak\"]), color='chocolate',zorder=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66306ea-eb2d-446c-960b-6d1f1879e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60a3803-05c8-46b9-a4ae-7621d9e4d1ef",
   "metadata": {},
   "source": [
    "## Crossmatching Highly Variable Candidates With Catalogue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88df2bf-9398-4095-bfc2-c7482cc1ba87",
   "metadata": {},
   "source": [
    "Our crossmatched catalogue only contains those sources that were detected by both ZTF and VAST. And thats great, but not all of those sources are either very variable or statistically significant or both. What we want to do know is crossmatch the crossmatch: find the sources within our VAST/FINK catalogue which are ALSO highly variable and statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71615e6-c3b7-4dc2-8394-7cfb3655a6cf",
   "metadata": {},
   "source": [
    "Thankfully, by performing our Eta-V Analysis, we already have our list of sources which fit the bill..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828c03d8-429b-485c-9bb9-f1646e74f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we already got the VAST info on our crossmatched sources through sel. we just need to filter for the highly variable\n",
    "#sources based on the eta and v threshholds we calculated before:\n",
    "candidate_sel = sel[(sel['eta_peak'] >= eta_thresh) & (sel['v_peak'] >= v_thresh)]\n",
    "\n",
    "#getting the sel_candidate ids is squirrely, since they're the row INDEX of the dataframe. \n",
    "#passing eta_v_candidates['id'] will not work. The below code pulls out those index values as a string list:\n",
    "candidate_ids=candidate_sel.index.values.astype('str').tolist()\n",
    "\n",
    "#then we just check how many objects in cmf have an id that match the candidate ids\n",
    "candidate_cmf=cms[cms['matched_id'].isin(candidate_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da92d3b6-0afb-4ee2-882a-836a595e8c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can check to see the size of each family.\n",
    "candidate_cms.groupby('family').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303edf7d-859e-49a0-a9cd-d91a544da313",
   "metadata": {},
   "source": [
    "The ETA - V filtering thats been conducted above is also handled by the 'eta_v_analysis' function present in Projecttools.py, if you input the recorded eta_thresh and v_thresh that the initial analysis outputted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c189ae-497b-4d1c-94a5-c087eb086c94",
   "metadata": {},
   "source": [
    "## Duplicate Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a65fa9-d34f-4828-b4ff-7fa145953fd1",
   "metadata": {},
   "source": [
    "Here, you can check if there happens to be any duplicate sources that might be present in your crossmatch catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b63a6-045e-41dc-a178-dea21ab7bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This looks for rows in cmf that have the same value for 'matched_id'. it dosent ignore the first instance of an id occuring\n",
    "dup=cms[cms.duplicated(subset=['matched_id'],keep=False) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd0578b-014c-46d4-a0f8-c4c007cc7532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying every duplicate row\n",
    "pd.options.display.max_rows = None\n",
    "dup.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2d92f-ddd1-4df1-936e-a119dbf74870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is the list of unique ids that are duplicates\n",
    "pd.unique(dup['matched_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0024230-117b-4582-a2c4-8592f4769d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here you can go through and pull out rows and their duplicates to see the difference\n",
    "dup.query('matched_id == \"3322564\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
