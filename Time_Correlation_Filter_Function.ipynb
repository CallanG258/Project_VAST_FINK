{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "556dcc84-7c0a-41a0-9850-6ba5020859cc",
   "metadata": {},
   "source": [
    "# Time Correlation Filter Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d682074a-e292-41fd-8d7a-ed22fca67072",
   "metadata": {},
   "source": [
    "The Purpose of this Notebook will be to to plan and test a time correlation function that will filter sources depending on how well its opitcal and radio data lines up timewise.\n",
    "\n",
    "The goal so far is to collect the optical and radio data for all the eta-v filtered sources (206 of them), and put them into two dataframes: fsd for FINK data and vsd for VAST data.\n",
    "\n",
    "I've managed to construct vsd fine, but I'm having issues constructing fsd. when I run the portal request for the full list of sources, even with batching, the kernel appears to die and the notebook is reset. This happens even when the request is contained in a function I've called 'query_fink_db', which you can find in Projecttools.py. This Kernel restart error dosent happen if the ID list is sufficiently small (I tested 12 IDS with batching and it worked fine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d8db54e-87e5-4e32-9c84-3bec7e637f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here are the necessary imports\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from io import StringIO\n",
    "from vasttools.pipeline import Pipeline\n",
    "from vasttools.query import Query\n",
    "import Projecttools as pro #brand new module for frequently used code!\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c40ac35-c9a0-4c53-aabd-686d1c03b548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "family\n",
       "AGN                827\n",
       "Unknown            516\n",
       "Galaxy             167\n",
       "Solar System        81\n",
       "Radio               70\n",
       "Supernova           51\n",
       "Multiwavelength     39\n",
       "Star                21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cms = pd.read_pickle('Fink_2020_sources_matched_to_VAST_all_sources.pickle')\n",
    "pro.family_sort(cms)\n",
    "cms.groupby('family').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d59a49e2-e45f-4558-9ae3-bd3b98e0494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/vasttools/pipeline.py:2609: UserWarning: Measurements have been loaded with vaex.\n",
      "  warnings.warn(\"Measurements have been loaded with vaex.\")\n"
     ]
    }
   ],
   "source": [
    "#This will automatically find the base directory that needed to be specified\n",
    "pipe=Pipeline()\n",
    "#this way, we can also load specific runs from the VAST pipeline:\n",
    "my_run=pipe.load_run('tiles_corrected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c69269-3a06-4317-90cd-b148cf31789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Im just putting the eta and v threshholds because the eta-v analysis takes an actual eternity to complete and I already\n",
    "#have the values here:\n",
    "eta_thresh=2.315552652171963\n",
    "v_thresh=0.2878888414273631"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73524f20-82dc-436d-9a4e-e0c3bb7d0b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 213 candidate sources:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "family\n",
       "AGN                93\n",
       "Unknown            53\n",
       "Solar System       30\n",
       "Galaxy             15\n",
       "Radio               9\n",
       "Star                5\n",
       "Multiwavelength     4\n",
       "Supernova           4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cms_candidates = pro.eta_v_candidate_filter(cms,my_run,eta_thresh,v_thresh)\n",
    "cms_candidates.groupby('family').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec984dd-7a19-4e66-8c2e-8119d20dc165",
   "metadata": {},
   "source": [
    "I will be testing out this function on the ETA-V filtered sources. In order for this to work, I need to have both the radio and optical data available for each source. Since the FINK broker has a limit as to how many sources can be queried at a time, I've done some \"Batching:\" breaking up the ID list into batches, running the portal query, and stitching the results of each batch together into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b915b732-009b-4010-9d83-cce49254a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These IDs are selected from the curated list of interesting sources (lightcurves can be seen via powerpoint.)\n",
    "Idlist=cms_candidates['objectId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf7c2e-20a2-41fc-b7e3-031691dce8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_elem=len(Idlist)#length of id list\n",
    "num_chunks=num_elem//30+1 #number of chunks, based on how you want to divide them up. in this case, 10 IDS per chunk\n",
    "list_chunks=(np.array_split(np.arange(num_elem), num_chunks))#np.arange(num_elem) makes an ordered array, from 0 to (num_elem - 1).\n",
    "                                                            #np.array_split splits said ordered array according to the number of chunks specified by num_chunks\n",
    "                                                            #each chunk is an element in the array 'list_chunks'\n",
    "for i in list(range(len(list_chunks))):\n",
    "    list_chunks[i]=list_chunks[i].tolist()\n",
    "\n",
    "#defining column array for cutouts\n",
    "cutouts=[\n",
    "'b:cutoutScience_stampData',\n",
    "'b:cutoutTemplate_stampData',\n",
    "'b:cutoutDifference_stampData'\n",
    "]\n",
    "\n",
    "for chunk_idx in list_chunks: #for each chunk in list_chunks\n",
    "    start,end=chunk_idx[0],chunk_idx[-1]+1 #define the starting and ending indexes for the given chunk\n",
    "\n",
    "    #this is the request made to the fink portal to pull out the info for each source\n",
    "    #df_tmp=pro.query_fink_db(Idlist[start:end])\n",
    "    r = requests.post(\n",
    "        'https://fink-portal.org/api/v1/objects',\n",
    "        json={\n",
    "        'objectId': ','.join(Idlist[start:end]), #This is where the 'chunk_idx[-1] +1' comes into play. the 'end' variable when slicing the list is inclusive of the index.\n",
    "        'output-format': 'json'\n",
    "        #'withcutouts': 'False',\n",
    "        #'columns': 'i:objectId,v:firstdate,v:lastdate',\n",
    "        #'cols': ','.join(cutouts),\n",
    "        #'withupperlim': 'True' #important for lightcurve plotting\n",
    "        }\n",
    "    )\n",
    "    df_tmp=pd.read_json(StringIO(r.content.decode()))#define a temporary dataframe that holds the queried sources from the chunk\n",
    "    #saves the temporary dataframe to a folder as a .pkl file. the naming is based on which batch we're looking at\n",
    "    df_tmp.to_pickle('/home/jovyan/work/Project_VAST_FINK/FINK_Batches/Batch_{}.pkl'.format(list_chunks.index(chunk_idx)+1))\n",
    "    #clears memory from jupyter to help it not get stuck.\n",
    "    gc.collect()\n",
    "\n",
    "list_df=[] #empty array to hold fink sources.\n",
    "\n",
    "for chunk_idx in list_chunks:\n",
    "    #now, we're loading back in all the batches we saved and appending/concatonating them all back together into one dataframe: fsd\n",
    "    df_tmp=pd.read_pickle('/home/jovyan/work/Project_VAST_FINK/FINK_Batches/Batch_{}.pkl'.format(list_chunks.index(chunk_idx)+1))\n",
    "    list_df.append(df_tmp)\n",
    "fsd_load=pd.concat(list_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d83763-d283-429e-9740-2e615a12e42c",
   "metadata": {},
   "source": [
    "Alternatively, If you've already got fsd saved as a pickle file, load it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf8af0dc-5c31-4f28-ac08-199ebac2d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsd=pd.read_pickle('FINK_Batches/FSD_No_Upperlim.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9370fffc-222a-448f-adba-29bf32f0615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will convert the 'i:jd' column into MjD and rename the column to 'i:mjd'\n",
    "fsd['i:jd']=fsd['i:jd']-2400000.5\n",
    "fsd.rename(columns={\"i:jd\": \"i:mjd\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "909904bc-c97b-48fc-a2e7-47604314aed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This will have 213, as some IDs are tied to duplicaes.\n",
    "len(fsd['i:objectId'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da22b65-6165-4285-9808-e65114f89991",
   "metadata": {},
   "source": [
    "As you can see below, the radio data is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c940c983-79a2-4c6f-8899-abfded4c10c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#at the end, I turn the vaex Dataframelocal object into a pandas dataframe directly (our list of sources is not that large)\n",
    "vsi=[]\n",
    "for i in Idlist:\n",
    "    y=cms_candidates[cms_candidates['objectId'] == i]['matched_id'].astype(int).values[0]\n",
    "    vsi.append(y)\n",
    "meas=my_run.measurements\n",
    "vsd=meas[meas.source.isin(vsi)].to_pandas_df()\n",
    "\n",
    "#This will convert the 'time' column in vsd into MJD. The difference between JD and MJD is 2400000.5\n",
    "vsd['time']=vsd['time'].apply(pd.Timestamp.to_julian_date)-2400000.5\n",
    "vsd.rename(columns={\"time\": \"time_mjd\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "706c65cf-9ffa-49e3-82dc-5fdd2631e974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#that should have a length of 206, because, we're neglecting duplicate lines\n",
    "len(vsd['source'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573cf4cb-4696-46cf-95d2-fa1154b6312c",
   "metadata": {},
   "source": [
    "finally, for this function to work, it needs to know which Optical and Radio IDs correspond to the same source, so it can pull out the appropriate rows in fsd and vsd to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64777a60-951a-4444-9b87-ccce848edb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this takes the FINK and VAST IDs from the crossmatch catalogue and puts them into a dataframe, resetting the index.\n",
    "cml=pd.DataFrame({\"FINK ID\": cms_candidates['objectId'], \"VAST ID\": cms_candidates['matched_id']}).reset_index()\n",
    "#this drops the 'index' column leftover from cms_candidates\n",
    "cml.drop('index', inplace=True, axis=1)\n",
    "cml['VAST ID']=cml['VAST ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8cc118f-0a3a-49ec-a64e-edbf3e88052e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FINK ID</th>\n",
       "      <th>VAST ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZTF18acalcri</td>\n",
       "      <td>4141677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZTF19aamtyjb</td>\n",
       "      <td>3925789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZTF19ablxcfu</td>\n",
       "      <td>4152155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZTF19abnevdi</td>\n",
       "      <td>3880532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZTF19abxtqqt</td>\n",
       "      <td>3601365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>ZTF20aapskkf</td>\n",
       "      <td>3952105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>ZTF20aazjjqz</td>\n",
       "      <td>3444377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>ZTF20abaaaul</td>\n",
       "      <td>4001263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>ZTF20abxmrgk</td>\n",
       "      <td>3460721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>ZTF20ackaxrr</td>\n",
       "      <td>3609606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          FINK ID  VAST ID\n",
       "0    ZTF18acalcri  4141677\n",
       "1    ZTF19aamtyjb  3925789\n",
       "2    ZTF19ablxcfu  4152155\n",
       "3    ZTF19abnevdi  3880532\n",
       "4    ZTF19abxtqqt  3601365\n",
       "..            ...      ...\n",
       "208  ZTF20aapskkf  3952105\n",
       "209  ZTF20aazjjqz  3444377\n",
       "210  ZTF20abaaaul  4001263\n",
       "211  ZTF20abxmrgk  3460721\n",
       "212  ZTF20ackaxrr  3609606\n",
       "\n",
       "[213 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2072dab7-98a9-40f1-a06b-5a28e483f6aa",
   "metadata": {},
   "source": [
    "Ok! Now that we have cml, fsd and vsd, we can begin to construct our time overlap function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbc95d00-7855-494c-903b-3a7c72d9a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preamble\n",
    "Overlap=[]\n",
    "O=3\n",
    "R=3\n",
    "#x=True\n",
    "#overlap.append(x)\n",
    "ftd=pd.DataFrame({\"i:objectId\": fsd['i:objectId'], \"i:mjd\":fsd['i:mjd']})\n",
    "vtd=pd.DataFrame({\"source\": vsd['source'], \"time_mjd\": vsd['time_mjd']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5c870ee-5e41-4030-9791-a7deabf5eeee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ZTF19abnevdi', 3880532)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i represents the index of the row selelcted in cml. x and y are then the FINK and VAST IDs of that row respectively\n",
    "i=3\n",
    "x,y= cml.iloc[[i]]['FINK ID'][i], cml.iloc[[i]]['VAST ID'][i]\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9aad3098-540f-41f7-856e-39a5e84ff4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#these are all the rows in fsd that have the same FINK ID as the selected row in cml\n",
    "ftd_temp=ftd[ftd['i:objectId']==x]\n",
    "ftd_temp=ftd_temp.sort_values('i:mjd').reset_index()\n",
    "ftd_temp.drop('index', inplace=True, axis=1)\n",
    "ftd_temp.index.to_list()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3fe162-50a4-4ea9-bca5-dabc975d49d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# j represents the jth index in ftd_temp. start is the start date at the jth row, end is the row O rows ahead.\n",
    "j=0\n",
    "start=ftd_temp.iloc[[j]]['i:mjd'][j]\n",
    "end=ftd_temp.iloc[[j+O]]['i:mjd'][j+O]\n",
    "print(start)\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b3c4be-bbd2-4c01-b321-e7401f938b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are all the rows in vsd that have the same VAST ID as the selected row in cml\n",
    "vtd_temp=vtd[vtd['source']==y]\n",
    "vtd_temp=vtd_temp.sort_values('time_mjd').reset_index()\n",
    "vtd_temp.drop('index', inplace=True, axis=1)\n",
    "vtd_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e48fd-6477-41e4-ae67-2e6e8d43bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will check which values within vtd_temp are between the start and end dates defined\n",
    "overlap_temp=vtd_temp['time_mjd'].between(start,end)\n",
    "\n",
    "#this will pull out all instances where there a radio point was between the given range and count them. If there were none, this will output a length of 0 (empty set)\n",
    "len(overlap_temp[overlap_temp==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd19b4ba-1c7f-4806-8d5a-aa42829b8ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(overlap_temp[overlap_temp==True]) >= R:\n",
    "    Overlap.append(True)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "077c0125-1a3b-4a83-a546-ba588f3b0c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151, 62)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preamble\n",
    "Overlap = []\n",
    "O = 3\n",
    "R = 3\n",
    "\n",
    "ftd = pd.DataFrame({\"i:objectId\": fsd['i:objectId'], \"i:mjd\":fsd['i:mjd']})\n",
    "vtd = pd.DataFrame({\"source\": vsd['source'], \"time_mjd\": vsd['time_mjd']})\n",
    "\n",
    "#i represents the index of the row selelcted in cml. x and y are then the FINK and VAST IDs of that row respectively\n",
    "for i in cml.index.to_list():\n",
    "    FINK_ID,VAST_ID = cml.iloc[[i]]['FINK ID'][i], cml.iloc[[i]]['VAST ID'][i]\n",
    "    \n",
    "    #these are all the rows in fsd that have the same FINK ID as the selected row in cml\n",
    "    ftd_temp = ftd[ftd['i:objectId'] == FINK_ID]\n",
    "    ftd_temp = ftd_temp.sort_values('i:mjd').reset_index()\n",
    "    ftd_temp.drop('index', inplace=True, axis=1)\n",
    "    \n",
    "    #these are all the rows in vsd that have the same VAST ID as the selected row in cml\n",
    "    vtd_temp = vtd[vtd['source'] == VAST_ID]\n",
    "    vtd_temp = vtd_temp.sort_values('time_mjd').reset_index()\n",
    "    vtd_temp.drop('index', inplace=True, axis=1)\n",
    "    \n",
    "    # j represents the jth index in ftd_temp. start is the start date at the jth row, end is the row O-1 steps ahead.\n",
    "    for j in ftd_temp.index.to_list():\n",
    "        \n",
    "        #if we've reached the end of the list and the loop hasnt broken, it means we havent found any good overlap.\n",
    "        if j+O-1 > ftd_temp.index.to_list()[-1]:\n",
    "            Overlap.append(False)\n",
    "            break\n",
    "        \n",
    "        start, end = ftd_temp.iloc[[j]]['i:mjd'][j], ftd_temp.iloc[[j+O-1]]['i:mjd'][j+O-1]\n",
    "        #this checks which points in vtd_temp are with the range between start and end\n",
    "        overlap_temp = vtd_temp['time_mjd'].between(start,end)\n",
    "        \n",
    "        #If the number of points wthin that range is >= R, we have good overlap!\n",
    "        if len(overlap_temp[overlap_temp==True]) >= R:\n",
    "            Overlap.append(True)\n",
    "            break\n",
    "\n",
    "Overlap.count(False),Overlap.count(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
